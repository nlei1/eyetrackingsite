<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=lhDjYqiy3mZ0x6ROQEUoUw);ol{margin:0;padding:0}table td,table th{padding:0}.c7{border-right-style:solid;border-bottom-color:#cccccc;border-top-width:0pt;border-right-width:0pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:468.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c4{border-right-style:solid;border-bottom-color:#cccccc;border-top-width:0pt;border-right-width:0pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:608.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c8{border-right-style:solid;border-bottom-color:#cccccc;border-top-width:0pt;border-right-width:0pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:608.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c6{background-color:#ffc3c3;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Consolas";font-style:normal}.c10{background-color:#e1c8be;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Consolas";font-style:normal}.c1{background-color:#b3e2a9;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Consolas";font-style:normal}.c11{background-color:#f8cea3;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Consolas";font-style:normal}.c15{background-color:#d9dbdd;color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c0{background-color:#abd5ef;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Consolas";font-style:normal}.c9{background-color:#c3e2e1;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Consolas";font-style:normal}.c22{background-color:#d9dbdd;color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Consolas";font-style:normal}.c21{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c18{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c5{padding-top:0pt;padding-bottom:0pt;line-height:2.0;text-align:right}.c3{padding-top:0pt;padding-bottom:0pt;line-height:2.0;text-align:left}.c28{border-spacing:0;border-collapse:collapse;margin-right:auto}.c12{background-color:#e1c8be;font-size:12pt;font-weight:700}.c13{background-color:#ffc3c3;font-size:12pt;font-weight:700}.c19{background-color:#ffffff;max-width:1080pt;padding:72pt 72pt 72pt 72pt}.c14{orphans:2;widows:2;height:11pt}.c26{background-color:#f8cea3;font-weight:700}.c20{background-color:#abd5ef;font-weight:700}.c24{background-color:#b3e2a9;font-weight:700}.c25{background-color:#c3e2e1;font-weight:700}.c27{height:11pt}.c23{background-color:#d9dbdd}.c17{font-size:12pt}.c2{height:22.5pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c19 doc-content"><p class="c21"><span class="c17 c18">Legend:</span></p><p class="c21"><span class="c17 c25">Contribution</span><span class="c17">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c17 c26">Context/Status Quo</span><span class="c17">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c17 c20">Methodology</span><span class="c17">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c12">Goal/Focus</span><span class="c17">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c13">System Characteristics</span><span class="c17">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c17 c24">Participants</span><span class="c17">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c17 c22">Example</span></p><p class="c21 c27"><span class="c15"></span></p><p class="c3 c14"><span class="c16"></span></p><a id="t.b59384726fe12abdb42d4fbcda1fad795880a9a8"></a><a id="t.0"></a><table class="c28"><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">In this paper, we explore potential bias in sentiment analysis tools</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c11">&nbsp;in the context of Bengali communities</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">In this paper, we use video analysis to study two robotic trashcans</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c11">&nbsp;deployed in a busy city square.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">Drawing on 449 survey responses from a representative sample</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c11">&nbsp;in the United Kingdom</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To seize machine learning&#39;s potential for GUIs more efficiently</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, Graph4GUI exploits graph neural networks to capture individual elements&#39; properties and </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To explore this topic</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we used a design-based implementation research (DBIR) and community-based participatory </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">Addressing this gap</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we conducted a controlled experiment</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To address this</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c0">, our study introduces a comprehensive framework</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To mitigate the risks</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we developed a video-based monitoring system that incorporates different </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To meet these goals</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we model a customization as a sequence of content tokens, each with a set of adjustable </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To mitigate the risks</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we developed a video-based monitoring system that incorporates different </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To clarify these issues</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we first investigated how users perceive countdowns &quot;from 35/10 to 0&quot; and count-ups &quot;from </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To bridge the gap</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we conducted the first in-depth analysis of ChatGPT answers to 517 programming questions</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To this end</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we carried out a preregistered between-subjects controlled study (N = 680) spanning five </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To bridge this gap</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we conducted semi-structured interviews</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To investigate the effectiveness of such an approach</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we developed and delivered two anti-phishing trainings, group discussion and role-playing</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To understand this policy&#39;s impact</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">, we investigated 100 top-ranked US universities&#39; directory information sharing practices.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">Using Design-Based Research methodology</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c9">, we identified students&#39; Al-related privacy learning needs and developed six education </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">Across five experiments</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c9">, we provide evidence for a possible solution.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">Based on in-depth interviews with 10 practitioners and educators</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c9">, we explore the factors contributing to the preference for digital-first prototypes and &nbsp; &nbsp;</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">However, we argue &amp; demonstrate that thin devices are not enough</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to maximize the users dexterity.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">This study introduces a design space for tangible cubes in MR</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">, focusing on interaction space, visualization space, sizes, and multiplicity.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">This paper presents a large-scale controlled study</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;of how 120 beginning coders across three academic institutions approach writing and editing </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We propose an online Bayesian Optimization (BO)-based method</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;for rapidly determining the user-specific optimal settings of wrist based pointing.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">This paper investigates the use of through-skull sound conduction</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to authenticate smartglass users.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">This paper investigates new data exploration experiences</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;that enable blind users to interact with statistical data visualizations</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">Through a large online experiment</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">, we compare the utility of conformal prediction sets to displays of Top-$1$ and Top-$k$ </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">This paper presents a first hand account of ideating Al concepts</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to improve critical care medicine.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We present an interview study (n = 17)</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c1">&nbsp;of participants who use online platforms to seek information about their mental illnesses.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We collected and analyzed Instagram direct messages (DMs)</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c1">&nbsp;from 173 youth aged 1321 (including 86 LGBTQ+ youth).</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We conducted an ethnographically-informed study</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c1">&nbsp;with 28 participants (9 autistic Young Adults or &quot;YAs&#39;&quot; in need of substantial daily </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We conducted role-playing exercises</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c1">&nbsp;with 24 US journalists</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We conducted a qualitative study</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c1">&nbsp;with 16 blind and visually impaired (BI) developers</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We conducted quantitative (n=70) and qualitative (n=30) studies</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c1">&nbsp;with healthcare experts</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We conducted a collaborative, user-centered design study</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c1">&nbsp;with a team of scientific researchers</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We conducted a study</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c1">&nbsp;with 12 blind SR users</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We present and evaluate the concept of winds</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c11">&nbsp;-- micro challenges to be done in the physical world post-smartphone overload</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">In this study, we examine the use of visualising a robots uncertainty</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c11">&nbsp;in a high-stakes assisted decision-making task.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">Thus, we tested a social virtual world</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c11">&nbsp;that is transparent about others&#39; avatar-creation methods</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c10">To bridge this gap</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c1">, we interviewed eight deaf and hard of hearing (dHH) audio engineers in music</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We implemented a Figma plugin</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">&nbsp;that takes in a UI design and a set of written heuristics, and renders </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We deployed a mobile robotic partition</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c6">&nbsp;that autonomously manoeuvres between predetermined locations.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We introduce Wikibench</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a system that enables communities to collaboratively curate Al evaluation datasets, while </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">Based on these findings, we introduce FoodCensor</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, an intervention designed to empower individuals with eating disorders to make informed, </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We present SolarClub</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a demand-shifting visualization system that supported households in coordinating their </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">we introduce Signmaku</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a commenting mechanism that uses ASL as a sign language version of danmaku.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">Therefore, we proposed EyeVis</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a prototype that can visualize the residual eye makeup and record the time make-up was </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We present COMPA</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c6">, an add-on tool for online group conversations</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We developed DungeonMaker</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a fabrication-augmented HBG bridging physical and digital game elements.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We present Large Language Model for Mixed Reality (LLMR)</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a framework for the real-time creation and modification of interactive Mixed Reality </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We introduce a VR body swap system</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c6">&nbsp;enabling multiple users to swap their perspectives and appearances</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">we created Be.side</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a fully customisable multi-modal artefact that incorporates scent, sound, and heartbeat </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">In this study, we introduce FocusFlow</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a hands-free interaction method that capitalizes on human visual depth perception within </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We propose (N=20) a novel AR permission control system</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c6">that allows better-informed privacy decisions</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We developed CUPS</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a taxonomy of common programmer activities</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We developed MindShift</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a novel LLM-powered problematic smartphone use intervention technique.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">we present PepperPose</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a novel companion robot system tailored for optimized pose estimation.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">This paper presents TypeDance</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, an Al-assisted tool incorporating design rationales with the generative model</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We present Tandem</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a software library that lets a fabricator implement an end-to-end fabrication workflow as </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We propose TensionFab</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a novel technique for creating shape-changeable room-scale structures.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">we designed and developed Talaria</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c6">: a model visualization and optimization system.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We thus present iPose</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, an interactive tool that facilitates intuitive human pose reconstruction from a given </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We develop Time2Stop</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c6">, an intelligent, adaptive, and explainable JITAI system that</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">In this research, we developed PaperTouch</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, an approach to design paper based mechanisms that translate a variety of physical </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">In this paper, we introduce EyeEcho</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a minimally-obtrusive acoustic sensing system designed to enable glasses to continuously </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">We present IntelliTex</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a low-cost and highly accessible double-coating fabrication method for washable and </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">In this paper, we present ClassInSight</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">, a tool that visualizes three levels of teachers discussion data and structures reflection.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">In this work, we propose Paired-EMS</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c6">&nbsp;which simultaneously stimulates both the muscles that users activate and that prior EMS </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We conducted four studies</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c16 c23">, including an examination of accessibility reports from European Member-states, interviews </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c6">STMG increases the gesture space</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">&nbsp;by recognizing additional small thumb- based microgestures from skeletal tracking running &nbsp;</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">In this study, we developed five low-fidelity prototypes as probes</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to explore the design requirements for caregiver-facing values elicitation tools</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">This study more holistically explores visualization interpretation</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to examine the alignment between designers&#39; communicative goals and what their audience </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">In this work, we first conducted preliminary studies</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to understand the influence of targeted clickbait on users&#39; clicking behavior.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We first qualitatively analyzed 40 nurse notes</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to identify challenges nurses encounter gathering information due to language barriers.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">In this study, we interviewed 20 programming- based CAD users</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to understand their motivations and challenges.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We engaged in an iterative, multidisciplinary design process</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to envision clinically relevant VLM interactions</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We developed a conversational agent</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;to assist children in planning and accomplishing daily tasks, with the aim of enhancing </span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c0">We interviewed 18 LGBTQ+ and 13 non-LGBTQ+ participants</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c10">&nbsp;about their experiences with LLM-based chatbots for mental health needs.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">This paper teases apart the monolithic representation of PSAI</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c3"><span class="c0">&nbsp;by investigating system components that maximize value and mitigate concerns.</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">Hence, this paper presents a set of grand challenges</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c0">&nbsp;identified in a five-day workshop</span></p></td></tr><tr class="c2"><td class="c7" colspan="1" rowspan="1"><p class="c5"><span class="c9">This paper investigated existing tools</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c3"><span class="c0">&nbsp;with a framework from two perspectives</span></p></td></tr></table><p class="c3 c14"><span class="c16"></span></p><p class="c3 c14"><span class="c16"></span></p></body></html>